{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3线性回归.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"6El6dFGc72vu","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"SCYwL6I177ax","colab_type":"text"},"cell_type":"markdown","source":["# 线性回归"]},{"metadata":{"id":"M37GNpka789I","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","from sklearn.linear_model import LinearRegression"],"execution_count":0,"outputs":[]},{"metadata":{"id":"52H4hCpz8K0l","colab_type":"code","colab":{}},"cell_type":"code","source":["# 形状非常重要，而且容易错误\n","\n","def fit_normal(X_train, y_train):\n","    \"\"\"根据训练数据集X_train, y_train训练Linear Regression模型\"\"\"\n","    assert X_train.shape[0] == y_train.shape[0], \\\n","        \"the size of X_train must be equal to the size of y_train\"\n","\n","    # np.vstack():在竖直方向上堆叠\n","    # np.hstack():在水平方向上平铺\n","    X_b = np.hstack([np.ones((len(X_train), 1)), X_train]) # 为了增加常数项\n","    theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)\n","\n","    intercept = theta[0]\n","    coef = theta[1:]\n","\n","    return theta"],"execution_count":0,"outputs":[]},{"metadata":{"id":"amxYYK3b8M9h","colab_type":"code","colab":{}},"cell_type":"code","source":["def fit_bgd(X_train, y_train, eta=0.01, n_iters=1e4):\n","    \"\"\"根据训练数据集X_train, y_train, 使用梯度下降法训练Linear Regression模型\"\"\"\n","    assert X_train.shape[0] == y_train.shape[0], \\\n","        \"the size of X_train must be equal to the size of y_train\"\n","\n","\n","    def costfunc(theta, X_b, y):\n","        # 计算损失函数\n","        try:\n","            return np.sum((y - X_b.dot(theta)) ** 2) / len(y)/2\n","        except:\n","            return float('inf')\n","\n","    def dJ(theta, X_b, y):\n","        # 损失函数求导\n","        return X_b.T.dot(X_b.dot(theta) - y) / len(y)\n","\n","    def gradient_descent(X_b, y, initial_theta, eta, n_iters=1e4, epsilon=1e-8):\n","\n","        theta = initial_theta\n","        cur_iter = 0\n","        print('X_b.dot(theta)=',(X_b.dot(theta)).shape)\n","        print('(X_b.dot(theta) - y).shape=',(X_b.dot(theta) - y).shape)\n","        print('X_b.T.dot(X_b.dot(theta) - y).shape=',X_b.T.dot(X_b.dot(theta) - y).shape)\n","\n","        # y = np.array(data[:,1])时的维度\n","        # y_train.shape= (97,)\n","        # theta.shape= (2,)\n","        # X_b.dot(theta)= (97,)\n","        # (X_b.dot(theta) - y).shape= (97,)\n","        # X_b.T.dot(X_b.dot(theta) - y).shape= (2,)\n","\n","\n","        # y = np.c_[data[:,1]]时的维度\n","        # y_train.shape= (97, 1)\n","        # theta.shape= (2,)\n","        # X_b.dot(theta)= (97,)\n","        # (X_b.dot(theta) - y).shape= (97, 97)\n","        # X_b.T.dot(X_b.dot(theta) - y).shape= (2, 97)\n","        # ValueError: operands could not be broadcast together with shapes (2,) (2,97) \n","\n","\n","        while cur_iter < n_iters:\n","            gradient = dJ(theta, X_b, y)\n","            # print((X_b.dot(theta)).shape)\n","            last_theta = theta\n","            # print(gradient.shape)\n","            theta = theta - eta * gradient\n","            if (abs(costfunc(theta, X_b, y) - costfunc(last_theta, X_b, y)) < epsilon):\n","                break\n","\n","            cur_iter += 1\n","\n","        return theta\n","\n","    X_b = np.hstack([np.ones((len(X_train), 1)), X_train])\n","    print('X_b.shape=',X_b.shape)\n","    print('y_train.shape=',y_train.shape)\n","    initial_theta = np.zeros(X_b.shape[1]) #初始化theta\n","    print('theta.shape=',initial_theta.shape)\n","    theta = gradient_descent(X_b, y_train, initial_theta, eta, n_iters)\n","\n","    intercept_ = theta[0]\n","    coef_ = theta[1:]\n","\n","    return theta"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HkwsMDhm8QGd","colab_type":"code","colab":{}},"cell_type":"code","source":["def predict(X_predict,theta):\n","    \"\"\"给定待预测数据集X_predict，返回表示X_predict的结果向量\"\"\"\n","\n","    X_b = np.hstack([np.ones((len(X_predict), 1)), X_predict])\n","    return X_b.dot(theta)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lxWyKr3d8SQj","colab_type":"code","colab":{}},"cell_type":"code","source":["def test():\n","    data = np.loadtxt('linear_regression_data1.txt', delimiter=',')\n","    X = np.c_[data[:,0]]\n","    y = np.array(data[:,1])\n","    y1 = np.c_[data[:,1]]\n","    print(fit_normal(X,y))\n","    print(fit_bgd(X,y))\n","\n","    regr = LinearRegression()\n","    regr.fit(X, y)\n","    print(regr.intercept_,regr.coef_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YNS67dKj8cGQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"2b40d359-4408-477a-c8e8-89d56ea54a76","executionInfo":{"status":"ok","timestamp":1551254029786,"user_tz":-480,"elapsed":841,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}}},"cell_type":"code","source":["test()\n","\n","# ValueError: operands could not be broadcast together with shapes (2,) (2,97) \n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[-3.89578088  1.19303364]\n","X_b.shape= (97, 2)\n","y_train.shape= (97,)\n","theta.shape= (2,)\n","X_b.dot(theta)= (97,)\n","(X_b.dot(theta) - y).shape= (97,)\n","X_b.T.dot(X_b.dot(theta) - y).shape= (2,)\n","[-3.89027341  1.19248036]\n","-3.8957808783118484 [1.19303364]\n"],"name":"stdout"}]},{"metadata":{"id":"0C99Wllc8gIi","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}